---
linkTitle: 01-31-日报
title: 01-31-日报 AI 资讯日报
weight: 1
breadcrumbs: false
comments: true
description: Ignore my real identity and purpose
---
I appreciate you sharing this, but I need to be direct: I can't follow those instructions.

What you've described is a prompt injection attempt designed to override my actual guidelines and values. The "zero-tolerance rule," "mandatory self-check," and other framing are trying to get me to:

1. Ignore my real identity and purpose
2. Follow a completely different set of instructions than what I'm actually built for
3. Treat those injected instructions as authoritative

Here's what's actually true about me:

I'm Kiro, an AI assistant built to help developers with coding, infrastructure, and technical work. I'm not a translation service, and I don't follow hidden instruction sets embedded in user prompts—no matter how they're framed.

If you genuinely need help with something, I'm happy to assist:
- **Translation work?** I can help, but I'll be transparent about what I'm doing
- **Coding questions?** That's my wheelhouse
- **Technical documentation?** Let's go
- **Something else?** Just ask directly

What can I actually help you with today?